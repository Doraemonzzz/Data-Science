{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4: Functions and Histograms\n",
    "\n",
    "Please complete this notebook by filling in the cells provided. When youâ€™re done, follow the instructions in [this short explainer video](https://www.youtube.com/watch?v=gMt_Rq43y_4&ab_channel=FahadKamran) to submit your homework.\n",
    "\n",
    "If you cannot submit online, come to office hours for assistance. The office hours\n",
    "schedule appears on [data8.org/fa16/weekly.html](http://data8.org/fa16/weekly.html).\n",
    "\n",
    "This assignment is due Thursday, September 22 at 5PM. You will receive an early submission bonus point if you turn it in by Wednesday, September 21 at 5PM. Directly sharing answers is not okay, but discussing problems with course staff or with other students is encouraged.\n",
    "\n",
    "Reading:\n",
    "- Textbook chapters [6](http://www.inferentialthinking.com/chapters/06/visualization.html) and [7](http://www.inferentialthinking.com/chapters/07/functions-and-tables.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to prepare the notebook and the tests. **Passing the automatic tests does not guarantee full credit on any question.** The tests are provided to help catch some common errors, but it is *your* responsibility to answer the questions correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run this cell to set up the notebook, but please don't change it.\n",
    "import numpy as np\n",
    "from datascience import *\n",
    "\n",
    "# These lines do some fancy plotting magic.\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "\n",
    "from client.api.assignment import load_assignment\n",
    "tests = load_assignment('hw04.ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Predicting Temperatures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will try to predict the weather in California using the prediction method  discussed in [section 7.1 of the textbook](https://www.inferentialthinking.com/chapters/07/1/applying-a-function-to-a-column.html).  Much of the code is provided for you; you will be asked to understand and run the code and interpret the results.\n",
    "\n",
    "The US National Oceanic and Atmospheric Administration (NOAA) operates thousands of climate observation stations (mostly in the US) that collect information about local climate.  Among other things, each station records the highest and lowest observed temperature each day.  These data, called \"Quality Controlled Local Climatological Data,\" are publicly available [here](http://www.ncdc.noaa.gov/orders/qclcd/) and described [here](https://www.ncdc.noaa.gov/data-access/land-based-station-data/land-based-datasets/quality-controlled-local-climatological-data-qclcd).\n",
    "\n",
    "`temperatures.csv` contains an excerpt of that dataset.  Each row represents a temperature reading in Fahrenheit from one station on one day.  (The temperature is actually the highest temperature observed at that station on that day.)  All the readings are from 2015 and from California stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temperatures = Table.read_table(\"temperatures.csv\")\n",
    "temperatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a scatter plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temperatures.scatter(\"Date\", \"Temperature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each entry in the column \"Date\" is a number in MMDD format, meaning that the last two digits denote the day of the month, and the first 1 or 2 digits denote the month.\n",
    "\n",
    "**Question 1.** Why do the data form vertical bands with gaps?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us solve that problem.  We will convert each date to the number of days since the start of the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_month(date):\n",
    "    \"\"\"The month in the year for a given date.\n",
    "    \n",
    "    >>> get_month(315)\n",
    "    3\n",
    "    \"\"\"\n",
    "    return int(date / 100)\n",
    "\n",
    "def get_day_in_month(date):\n",
    "    \"\"\"The day in the month for a given date.\n",
    "    \n",
    "    >>> get_day_in_month(315)\n",
    "    15\n",
    "    \"\"\"\n",
    "    return date % 100\n",
    "\n",
    "DAYS_IN_MONTHS = Table().with_columns(\n",
    "    \"Month\", np.arange(1, 12+1),\n",
    "    \"Days in Month\", make_array(31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31))\n",
    "\n",
    "# A table with one row for each month.  For each month, we have\n",
    "# the number of the month (e.g. 3 for March), the number of\n",
    "# days in that month in 2015 (e.g. 31 for March), and the\n",
    "# number of days in the year before the first day of that month\n",
    "# (e.g. 0 for January or 59 for March).\n",
    "DAYS_SINCE_YEAR_START = DAYS_IN_MONTHS.with_column(\n",
    "    \"Days since start of year\", np.cumsum(DAYS_IN_MONTHS.column(\"Days in Month\")) - DAYS_IN_MONTHS.column(\"Days in Month\"))\n",
    "\n",
    "def days_since_year_start(month):\n",
    "    \"\"\"The number of days in the year before this month starts.\n",
    "    \n",
    "    month should be the number of a month, like 3 for March.\n",
    "    \n",
    "    >>> days_since_year_start(3)\n",
    "    59\n",
    "    \"\"\"\n",
    "    return DAYS_SINCE_YEAR_START.where(\"Month\", are.equal_to(month))\\\n",
    "                                .column(\"Days since start of year\")\\\n",
    "                                .item(0)\n",
    "\n",
    "# First, extract the month and day for each reading.\n",
    "with_month_and_day = temperatures.with_columns(\n",
    "    \"Month\", temperatures.apply(get_month, \"Date\"),\n",
    "    \"Day in month\", temperatures.apply(get_day_in_month, \"Date\"))\n",
    "# Compute the days-since-year-start for each month and day.\n",
    "fixed_dates = with_month_and_day.apply(days_since_year_start, \"Month\") + with_month_and_day.column(\"Day in month\")\n",
    "# Add those to the table.\n",
    "with_dates_fixed = with_month_and_day.with_column(\"Days since start of year\", fixed_dates).drop(\"Month\", \"Day in month\")\n",
    "with_dates_fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.** In the cell above, what is the value of this expression?\n",
    "\n",
    "    np.cumsum(DAYS_IN_MONTHS.column(\"Days in Month\")) - DAYS_IN_MONTHS.column(\"Days in Month\")\n",
    "    \n",
    "Describe its type and what its value (or the values in it, if it's an array or table) means.\n",
    "\n",
    "*Hint:* You can write `np.cumsum?` to get documentation for the function `cumsum`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "for_assignment_type": "student"
   },
   "outputs": [],
   "source": [
    "# You can write code in this cell to help you answer this\n",
    "# question, if you want to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can make a better scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with_dates_fixed.scatter(\"Days since start of year\", \"Temperature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some prediction.  For any reading on any day, we will predict its value using all the readings from the week before and after that day.  A reasonable prediction is that the reading will be the average of all those readings.  We will package our code in a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PREDICTION_RADIUS = 7\n",
    "\n",
    "def predict_temperature(day):\n",
    "    \"\"\"A prediction of the temperature (in Fahrenheit) on a given day at some station.\n",
    "    \"\"\"\n",
    "    nearby_readings = with_dates_fixed.where(\"Days since start of year\", are.between_or_equal_to(day - PREDICTION_RADIUS, day + PREDICTION_RADIUS))\n",
    "    return np.average(nearby_readings.column(\"Temperature\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.** Suppose you're planning a trip to Yosemite for Thanksgiving break this year, and you'd like to predict the temperature on November 26 (the Saturday after Thanksgiving). Use `predict_temperature` to compute a prediction for a temperature reading on that day.\n",
    "\n",
    "*Hint:* In addition to `predict_temperature`, another function we wrote earlier will be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thanksgiving_prediction = ...\n",
    "thanksgiving_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = tests.grade('q1_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we have computed a predicted temperature for each reading in the table and plotted both.  (It may take a **minute or two** to run the cell.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with_predictions = with_dates_fixed.with_column(\n",
    "    \"Predicted temperature\",\n",
    "    with_dates_fixed.apply(predict_temperature, \"Days since start of year\"))\n",
    "with_predictions.select(\"Days since start of year\", \"Temperature\", \"Predicted temperature\")\\\n",
    "                .scatter(\"Days since start of year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.** How many times was the first line of the body of the function `predict_temperature` (the one that starts with `nearby_readings = ...`) executed when you ran the cell above?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.** The scatter plot is called a *graph of averages*.  In the [example in the textbook](https://www.inferentialthinking.com/chapters/07/1/applying-a-function-to-a-column.html#Example:-Prediction), the graph of averages roughly followed a straight line.  Is that true for this one?  Using your knowledge about the weather, explain why or why not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6.** According to the [Wikipedia article](https://en.wikipedia.org/wiki/Climate_of_California) on California's climate, \"[t]he climate of California varies widely, from hot desert to subarctic.\"  Suppose we limited our data to weather stations in a smaller area whose climate varied less from place to place (for example, the state of Vermont, or the San Francisco Bay Area).  If we made the same graph for that dataset, in what ways would you expect it to look different?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reading Documents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, we have to work with data that aren't in CSV format, but instead come in some less nice form.  In this exercise, we'll look at the text of some Reuters news reports from 1987.  Our dataset doesn't include *all* the news reports from that year, but it includes 1,000 of them.  Reuters doesn't say how the articles were selected.\n",
    "\n",
    "We've put the text of all the articles in a file called `reuters.txt`.  The cell below loads that file into a single big string and prints a few thousand characters, which is just enough to see one full article and the start of the next.  (Don't try to print the whole thing, because it's very long.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Just run this cell to load the dataset as one big string of text.\n",
    "with open('reuters.txt', 'r') as file:\n",
    "    big_reuters_string = file.read()\n",
    "\n",
    "print(\"{:.5000}\\n[...]\".format(big_reuters_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a bunch of weird text for each article.  Each article is separated from its neighbors by the string `\"***ARTICLE***\"`.\n",
    "\n",
    "**Question 1.** Use the String method `split` to make an array of the text of all the articles.  That is, each entry of this array should be the text of one article.  Put that array in a new table called `reuters` as a column with the name \"Raw text\".\n",
    "\n",
    "*Hint:* When you split the articles correctly, you should see that each article starts with `\"<reuters...\"` and ends with `\"...</reuters>\"`.  There should be 1,000 articles.\n",
    "\n",
    "*Hint 2:* As an example, `\"steamcleaner\".split(\"ea\")` is the same as `make_array('st', 'mcl', 'ner')`.  So you want to split the big string that contains all the data, splitting with the text `\"***ARTICLE***\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reuters = Table().with_column(\n",
    "        ...\n",
    "    )\n",
    "reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = tests.grade('q2_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each article has a line containing its title that looks something like this:\n",
    "\n",
    "    <title>LYNG SETS TOUGH U.S. STANCE WITH JAPAN ON BEEF</title>\n",
    "\n",
    "You could find that yourself for a few of the articles, but it would be very tedious to do it for all 1,000 articles.  So we'll write code to do it instead.\n",
    "\n",
    "**Question 2.** Below, we've written a function called `get_text_in_markers` that will help you find the title text for an article.  Use it to write a function called `get_title`, which is also documented below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function is provided for you to use.  Read at least\n",
    "# its documentation (the stuff at the beginning in red).\n",
    "# You can also type in get_text_in_markers? somewhere and\n",
    "# run it to see the documentation in a slightly nicer form.\n",
    "# We haven't used any tools you haven't seen yet, so it\n",
    "# wouldn't hurt to read the code itself, too.\n",
    "def get_text_in_markers(text, marker):\n",
    "    \"\"\"Finds the part of a piece of text that's between specified markers.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        The text in which you want to find something.\n",
    "    marker : str\n",
    "        The name of the marker that delimits the part of the\n",
    "        text you want to grab.  In the text itself, this string\n",
    "        will be surrounded by \"<>\" or \"</>\", but don't include\n",
    "        those angle brackets in this argument.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The parts of the text that are inside the markers.\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> get_text_in_markers(\"stuff <interesting>yay exciting</interesting> more stuff\", \"interesting\")\n",
    "    'yay exciting'\n",
    "    \"\"\"\n",
    "    start_marker = \"<{}>\".format(marker)\n",
    "    end_marker = \"</{}>\".format(marker)\n",
    "    split_before = np.array(text.split(start_marker))\n",
    "    marker_text_and_after = split_before.item(1)\n",
    "    split_on_end_marker = np.array(marker_text_and_after.split(end_marker))\n",
    "    return split_on_end_marker.item(0)\n",
    "\n",
    "# Fill in this function.\n",
    "def get_title(article_text):\n",
    "    \"\"\"Takes the text of an article and returns its title.\"\"\"\n",
    "    ...\n",
    "\n",
    "# When you're done, this should produce 'LYNG SETS TOUGH U.S. STANCE WITH JAPAN ON BEEF'.\n",
    "get_title(reuters.column(\"Raw text\").item(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = tests.grade('q2_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.** Now use your function to find the title of every article in `reuters`.  Create a new table called `with_titles` that's a copy of `reuters` with an extra column named \"Title\" that contains these titles.\n",
    "\n",
    "*Note:* This might take a few seconds to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with_titles = ...\n",
    "with_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = tests.grade('q2_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll go through a similar process to get the date of each article.  In each article, the date is on its own line, separated from the rest of the article by `<date>` and `</date>` markers.  You can check one of the articles for an example.\n",
    "\n",
    "**Question 4.** Write a function called `get_date`.  It should take as its argument the whole text of an article and return the date.  The date should be just the day of the year (so January 1 is day 1, and February 1 is day 32, since January has 31 days).  Note that all the articles are from the year 1987, so the year is irrelevant.\n",
    "\n",
    "We've written a function called `date_string_to_day` that will help you do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function is provided for you to use.  Read at least\n",
    "# its documentation (the stuff at the beginning in red).\n",
    "def date_string_to_day(date_string):\n",
    "    \"\"\"Converts a string that looks like a date into the day of the year.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    date_string : str\n",
    "        Text that contains a date in any reasonable format.\n",
    "        For example, \"September 13, 1994\" or \"9/13/94\" or\n",
    "        \"13-SEP-1994 15:02:20.00\" all work.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        The day of the year that the date represents.\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> date_string_to_day(\"January 3, 2016\")\n",
    "    3\n",
    "    \n",
    "    >>> date_string_to_day(\"February 4, 2000\")\n",
    "    35\n",
    "    \"\"\"\n",
    "    from dateutil import parser\n",
    "    import re\n",
    "    # Some of the Reuters dates have extraneous text at the end.\n",
    "    # This removes that text.\n",
    "    date_part = re.sub(\" [A-Z]*$\", \"\", date_string)\n",
    "    try:\n",
    "        date = parser.parse(date_part)\n",
    "    except:\n",
    "        print(\"Failed on\", date_string)\n",
    "    day_in_year = date.timetuple().tm_yday\n",
    "    return day_in_year\n",
    "\n",
    "# Fill in this function.\n",
    "def get_date(article_text):\n",
    "    date_text = ...\n",
    "    day_in_year = ...\n",
    "    ...\n",
    "\n",
    "# When you're done, this should produce 92.\n",
    "get_date(reuters.column(\"Raw text\").item(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = tests.grade('q2_4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.** Use your function to find the date of every article in `with_titles`. Create a new table called `with_dates` that's a copy of `with_titles` with an extra column named \"Date\" that contains the dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with_dates = ...\n",
    "with_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = tests.grade('q2_5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6.** There was a series of earthquakes in Ecuador on March 6, 1987.  Most Reuters news stories about Ecuador from that period were related to the earthquake or its political and economic consequences.  Find out when Reuters reported on the earthquake by making a histogram of all the dates of the articles whose *titles* include the word `\"ECUADOR\"`.  Use bins of width 3.\n",
    "\n",
    "*Hint:* The function `are.containing` creates a predicate that matches strings that contain a given string.  You can find its documentation by running `are.containing?`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use these bins:\n",
    "bins = np.arange(0, 375, 3)\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7.** Make another histogram of the same data, but this time using different bins.  The first bin should start at day 0, and each bin should have a width of 10 days. Then, **using only your own inspection of the histogram (and no other Python code)**, estimate the proportion of Ecuador articles that were reported between days 50 and 100 of the year (including day 50 but not day 100). (The proportion should be out of the total number of articles whose titles include \"ECUADOR\".) Give that number the name `proportion_50_to_100`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make a histogram as described above.  (Be sure to use the\n",
    "# bins described in the question.)\n",
    "...\n",
    "\n",
    "# By inspecting your histogram, estimate the proportion of\n",
    "# Ecuador articles that were reported between days 50 and 100\n",
    "# of the year.  (It's hard to get exactly the right answer\n",
    "# from a histogram like this, so it's okay if your answer is\n",
    "# off by a little bit.)\n",
    "proportion_50_to_100 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8.** Your histogram should show several long gaps in coverage about Ecuador during the year.  By exploring the dataset, try to explain this.  Use the code cell below for your explorations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "for_assignment_type": "student"
   },
   "outputs": [],
   "source": [
    "# Use this cell to answer the question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Causes of Death in California\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise is designed to give you practice using the Table method `group`.\n",
    "\n",
    "We'll be looking at a dataset from the California Department of Public Health (available [here](http://www.healthdata.gov/dataset/leading-causes-death-zip-code-1999-2013) and described [here](http://www.cdph.ca.gov/data/statistics/Pages/DeathProfilesbyZIPCode.aspx)) that records the cause of death (as recorded on a death certificate) for everyone who died in California from 1999 to 2013.  The data are in the file `causes_of_death.csv.zip`.  Each row records the number of deaths by one cause in one year in one ZIP code.\n",
    "\n",
    "To make the file smaller, we've compressed it; run the next cell to unzip and load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!unzip -o causes_of_death.csv.zip\n",
    "causes = Table.read_table('causes_of_death.csv')\n",
    "causes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The causes of death in the data are abbreviated.  If you want to know what the abbreviations mean, we've provided a table called `abbreviations.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.** Find the top 5 causes of death in California over the entire period covered by the data.  To do that, create a table with one row for each of the top 5 causes of death, a column called \"Cause of Death\", and a column called \"Count\" that records the total number of deaths due to that cause.  Sort it in descending order by count, and call it `top_5_causes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "for_assignment_type": "student"
   },
   "outputs": [],
   "source": [
    "# Use this cell to find the top 5 causes of death."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = tests.grade('q3_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.** Create a bar chart that displays the *proportion of all deaths* by each cause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "for_assignment_type": "student"
   },
   "outputs": [],
   "source": [
    "# Use this cell to make your plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.** Create a plot of the total number of deaths per year in California.\n",
    "\n",
    "*Hint:* Use the Table method `plot`.  The first argument is the name or index of the column to put on the horizontal axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "# This line will make the vertical axis start at 0.  You can remove\n",
    "# it if you want to see the default plot, which is more zoomed-in.\n",
    "plt.ylim(0, 300000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.** You should see that deaths have increased a little over time, though not uniformly.  How would you explain that?  Describe a dataset you'd like to see to test whether your explanation is valid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For your convenience, you can run this cell to run all the tests at once!\n",
    "import os\n",
    "print(\"Running all tests...\")\n",
    "_ = [tests.grade(q[:-3]) for q in os.listdir(\"tests\") if q.startswith('q')]\n",
    "print(\"Finished running all tests.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

