{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 11: Classification, Two-Sample Tests, and Tables Review\n",
    "\n",
    "Please complete this notebook by filling in the cells provided. When youâ€™re done, follow the instructions in [this short explainer video](https://www.youtube.com/watch?v=gMt_Rq43y_4&ab_channel=FahadKamran) to submit your homework.\n",
    "\n",
    "If you cannot submit online, come to office hours for assistance. The office hours\n",
    "schedule appears on [data8.org/fa16/weekly.html](http://data8.org/fa16/weekly.html).\n",
    "\n",
    "This assignment is due **Monday, November 28 at 7PM**. You will receive an early submission bonus point if you turn it in by **Wednesday, November 23 at 7PM**.  (**Note the unusual dates!**)  Directly sharing answers is not okay, but discussing problems with course staff or with other students is encouraged.\n",
    "\n",
    "**Important note:** Only Parts 1 and 2 of this assignment will be graded.  Parts 3  (a review of table methods you'll need to use in Project 3) and 4 (on overfitting in classification and regression) will not be graded.\n",
    "\n",
    "**Note of optimism:** This is the last graded homework assignment of the semester.  You're almost done!\n",
    "\n",
    "Reading:\n",
    "- Textbook chapter [15](https://www.inferentialthinking.com/chapters/15/classification.html)\n",
    "- Textbook chapter [16](https://www.inferentialthinking.com/chapters/16/comparing-two-samples.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to prepare the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run this cell to set up the notebook, but please don't change it.\n",
    "import numpy as np\n",
    "from datascience import *\n",
    "\n",
    "# These lines do some fancy plotting magic.\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "from matplotlib import patches\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from client.api.assignment import load_assignment\n",
    "tests = load_assignment('hw11.ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reading Sign Language with Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brazilian Sign Language is a visual language used primarily by Brazilians who are deaf.  It is more commonly called Libras.  People who communicate with visual language are called *signers*.  Here is a video of someone signing in Libras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.lib.display import YouTubeVideo\n",
    "YouTubeVideo(\"mhIcuMZmyWM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Programs like Siri or Google Now begin the process of understanding human speech by classifying short clips of raw sound into basic categories called *phones*.  For example, the recorded sound of someone saying the word \"robot\" might be broken down into several phones: \"rrr\", \"oh\", \"buh\", \"aah\", and \"tuh\".  Phones are then grouped together into further categories like words (\"robot\") and sentences (\"I, for one, welcome our new robot overlords\") that carry more meaning.\n",
    "\n",
    "A visual language like Libras has an analogous structure.  Instead of phones, each word is made up of several *hand movements*.  As a first step in interpreting Libras, we can break down a video clip into small segments, each containing a single hand movement.  The task is then to figure out what hand movement each segment represents.\n",
    "\n",
    "We can do that with classification!\n",
    "\n",
    "The [data](https://archive.ics.uci.edu/ml/machine-learning-databases/libras/movement_libras.names) in this exercise come from Dias, Peres, and Biscaro, researchers at the University of Sao Paulo in Brazil.  They identified 15 distinct hand movements in Libras (probably an oversimplification, but a useful one) and captured short videos of signers making those hand movements.  (You can read more about their work [here](http://ieeexplore.ieee.org/Xplore/login.jsp?url=http%3A%2F%2Fieeexplore.ieee.org%2Fiel5%2F5161636%2F5178557%2F05178917.pdf&authDecision=-203). The paper is gated, so you will need to use your institution's Wi-Fi or VPN to access it.)\n",
    "\n",
    "For each video, they chose 45 still frames from the video and identified the location (in horizontal and vertical coordinates) of the signer's hand in each frame.  Since there are two coordinates for each frame, this gives us a total of 90 numbers summarizing how a hand moved in each video.  Those 90 numbers will be our *attributes*.\n",
    "\n",
    "Each video is *labeled* with the kind of hand movement the signer was making in it.  Each label is one of 15 strings like \"horizontal swing\" or \"vertical zigzag\".\n",
    "\n",
    "For simplicity, we're going to focus on distinguishing between just two kinds of movements: \"horizontal straight-line\" and \"vertical straight-line\".  We took the Sao Paulo researchers' original dataset, which was quite small, and used some simple techniques to create a much larger synthetic dataset.\n",
    "\n",
    "These data are in the file `movements.csv`.  Run the next cell to load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movements = Table.read_table(\"movements.csv\")\n",
    "movements.take(np.arange(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below displays movements graphically.  Run it and use the slider to answer the next question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Just run this cell and use the slider it produces.\n",
    "def display_whole_movement(row_idx):\n",
    "    num_frames = int((movements.num_columns-1)/2)\n",
    "    row = np.array(movements.drop(\"Movement type\").row(row_idx))\n",
    "    xs = row[np.arange(0, 2*num_frames, 2)]\n",
    "    ys = row[np.arange(1, 2*num_frames, 2)]\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(xs, ys, c=\"gold\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.xlim(-.5, 1.5)\n",
    "    plt.ylim(-.5, 1.5)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "\n",
    "def display_hand(example, frame, display_truth):\n",
    "        time_idx = frame-1\n",
    "        display_whole_movement(example)\n",
    "        x = movements.column(2*time_idx).item(example)\n",
    "        y = movements.column(2*time_idx+1).item(example)\n",
    "        plt.annotate(\n",
    "            \"frame {:d}\".format(frame),\n",
    "            xy=(x, y), xytext=(-20, 20),\n",
    "            textcoords = 'offset points', ha = 'right', va = 'bottom',\n",
    "            color='white',\n",
    "            bbox = {'boxstyle': 'round,pad=0.5', 'fc': 'black', 'alpha':.4},\n",
    "            arrowprops = {'arrowstyle': '->', 'connectionstyle':'arc3,rad=0', 'color': 'black'})\n",
    "        plt.scatter(x, y, c=\"black\", zorder=10)\n",
    "        plt.title(\"Hand positions for movement {:d}{}\".format(example, \"\\n(True class: {})\".format(movements.column(\"Movement type\").item(example)) if display_truth else \"\"))\n",
    "\n",
    "def animate_movement():\n",
    "    interact(\n",
    "        display_hand,\n",
    "        example=widgets.BoundedIntText(min=0, max=movements.num_rows-1, value=0, msg_throttle=1),\n",
    "        frame=widgets.IntSlider(min=1, max=int((movements.num_columns-1)/2), step=1, value=1, msg_throttle=1),\n",
    "        display_truth=fixed(False))\n",
    "\n",
    "animate_movement()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "#### Question 1\n",
    "Before we move on, check your understanding of the dataset.  Judging by the plot, is the first movement example a vertical motion, or a horizontal motion, or is it difficult to tell?  This is the kind of question a classifier has to answer.  Find out the right answer by looking at the `\"Movement type\"` column.  (It's okay if you guessed wrong for this one.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset\n",
    "We'll do 2 different kinds of things with the `movements` dataset:\n",
    "1. We'll build a classifier that uses the movements with known labels as examples to classify similar movements.  This is called *training*.\n",
    "2. We'll evaluate or *test* the accuracy of the classifier we build.\n",
    "\n",
    "For reasons discussed in lecture and the textbook, we want to use separate datasets for these two purposes.  So we split up our one dataset into two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "#### Question 2\n",
    "Create a table called `train_movements` and another table called `test_movements`.  `train_movements` should include the first $\\frac{11}{16}$ of the rows in `movements` (rounded to the nearest integer), and `test_movements` should include the remaining $\\frac{5}{16}$.\n",
    "\n",
    "*Hint:* Use the table method `take`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "for_assignment_type": "student"
   },
   "outputs": [],
   "source": [
    "training_proportion = 11/16\n",
    "num_movements = movements.num_rows\n",
    "num_train = int(round(num_movements * training_proportion))\n",
    "\n",
    "train_movements = ...\n",
    "test_movements = ...\n",
    "\n",
    "print(\"Training set:\\t\",   train_movements.num_rows, \"examples\")\n",
    "print(\"Test set:\\t\",       test_movements.num_rows, \"examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = tests.grade('q1_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using only 2 features\n",
    "First let's see how well we can distinguish two movements (a vertical line and a horizontal line) using the hand position from just a single frame (without the other 44)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "#### Question 3\n",
    "Make a table called `train_two_features` with only 3 columns: the x and y coordinates for the first frame, and the movement type; and only the examples in `train_movements`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_two_features = ...\n",
    "train_two_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = tests.grade('q1_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to make a scatter plot of the frame coordinates, where the dots for horizontal straight-line movements have one color and the dots for vertical straight-line movements have another color.  Here is a scatter plot without colors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_two_features.scatter(\"Frame 1 x\", \"Frame 1 y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't useful because we don't know which dots are which movement type.  We need to tell Python how to color the dots.  Let's use gold for vertical and blue for horizontal movements.\n",
    "\n",
    "`scatter` takes an extra argument called `colors` that's the name of an extra column in the table that contains colors (strings like \"red\" or \"orange\") for each row.  So we need to create a table like this:\n",
    "\n",
    "|Frame 1 x|Frame 1 y|Movement type|Color|\n",
    "|-|-|-|-|\n",
    "|0.522768|0.769731|vertical straight-line|gold|\n",
    "|0.179546|0.658986|horizontal straight-line|blue|\n",
    "|...|...|...|...|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "#### Question 4\n",
    "In the cell below, create a table named `with_colors`.  It should have the same columns as the example table above, but with a row for each row in `train_two_features`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You should find the following table useful.\n",
    "type_to_color = Table().with_columns(\n",
    "    \"Movement type\", make_array(\"vertical straight-line\", \"horizontal straight-line\"),\n",
    "    \"Color\",         make_array(\"gold\",                   \"blue\"))\n",
    "\n",
    "with_colors = ...\n",
    "with_colors.scatter(\"Frame 1 x\", \"Frame 1 y\", colors=\"Color\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = tests.grade('q1_4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "#### Question 5\n",
    "Based on the scatter plot, how well will a nearest-neighbor classifier based on only these 2 features (the x- and y-coordinates of the hand position in the first frame) work?  Will it:\n",
    "\n",
    "1. distinguish almost perfectly between vertical and horizontal movements;\n",
    "2. distinguish somewhat well between vertical and horizontal movements, getting some correct but missing a substantial proportion; or\n",
    "3. be basically useless in distinguishing between vertical and horizontal movements?\n",
    "\n",
    "Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "#### Question 6\n",
    "Imagine training a 1-nearest-neighbor classifier on this data.  For an example with first-frame coordinates (0.8, 0.9), what are the (rough) coordinates of the nearest point in the training set, and what is its class?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A classifier\n",
    "Now let's do nearest-neighbor classification.  In the interest of time, we'll do some of the steps for you.  Your job will be to *read and understand the given code* and use it to complete the classifier.\n",
    "\n",
    "In the following cell, we've defined three functions.  They're documented in the cell itself.  Unless you want to write your own classifier from scratch, use these to help you answer the next question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def euclidean_distance(a, b):\n",
    "    \"\"\"\n",
    "    The Euclidean distance (ordinary straight-line distance) between\n",
    "    the numbers in arrays a and b.\n",
    "    \n",
    "    You don't need to use this function; it's designed to be used\n",
    "    by the k_nearest_rows function below.\n",
    "    \"\"\"\n",
    "    return sum((a - b)**2)**0.5\n",
    "\n",
    "def k_nearest_rows(attributes, data, k):\n",
    "    \"\"\"\n",
    "    The k nearest neighbors in the data table to an observation with the given attributes.\n",
    "    \n",
    "    This function takes 3 arguments:\n",
    "     * attributes: An array of numbers, each one an attribute of the\n",
    "       observation whose neighbors we're finding.\n",
    "     * data: A table with many rows.  The columns in this table are\n",
    "       the attributes of the data (the same as the elements of the\n",
    "       attributes array), except that the last column is a label,\n",
    "       not a feature.  So data.num_columns should be 1 bigger than\n",
    "       len(attributes).\n",
    "     * k: The number of neighbors to find.\n",
    "    \n",
    "    It returns a table containing the k rows of data whose attributes\n",
    "    are closest in Euclidean distance to the attributes array.  The\n",
    "    returned table has the same columns as the data table.\n",
    "    \"\"\"\n",
    "    distances = make_array()\n",
    "    data_without_labels = data.drop(data.num_columns-1)\n",
    "    for i in np.arange(data.num_rows):\n",
    "        training_example_attributes = np.array(data_without_labels.row(i))\n",
    "        distance = euclidean_distance(attributes, training_example_attributes)\n",
    "        distances = np.append(distances, distance)\n",
    "    \n",
    "    return data.with_column(\"distance to observation\", distances)\\\n",
    "               .sort(\"distance to observation\")\\\n",
    "               .take(np.arange(k))\\\n",
    "               .drop(\"distance to observation\")\n",
    "\n",
    "def most_common(things):\n",
    "    \"\"\"\n",
    "    The most common element in an array of anything.\n",
    "    \n",
    "    This function takes 1 argument:\n",
    "     * things: An array containing any kind of data.\n",
    "    \n",
    "    It returns the most common element of that array.  For example,\n",
    "      most_common(make_array(0, 1, 1, 2, 1))\n",
    "    is 1, and\n",
    "      most_common(make_array(\"the\", \"I\", \"a\", \"I\"))\n",
    "    is \"I\".  If there's a tie, one of the most common elements is\n",
    "    chosen arbitrarily.  If the array is empty, an error will\n",
    "    happen.\n",
    "    \"\"\"\n",
    "    counts = Table().with_column(\"things\", things).group(\"things\")\n",
    "    return counts.sort(\"count\", descending=True).column(0).item(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "#### Question 7\n",
    "Below is the skeleton of a function that classifies examples as either vertical straight-line movements or horizontal straight-line movements.  Fill it in so that it does what its documentation promises.\n",
    "\n",
    "*Hint:* Use the functions we've defined for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill in this function.\n",
    "def classify(attributes, training_data, k):\n",
    "    \"\"\"\n",
    "    Classifies an observation with the given attributes.\n",
    "    \n",
    "    This function takes three arguments:\n",
    "     * attributes: An array of numbers.  Each is an attribute of a\n",
    "       movement.\n",
    "     * training_data: A table of observations.  Must have one column\n",
    "       for each attribute in the attributes array, *plus* one column\n",
    "       at the end containing the true class of each observation.\n",
    "     * k: The number of neighbors to look at.\n",
    "    \n",
    "    It returns a string, which is the name of the movement\n",
    "    type we guess for the given movement.\n",
    "    \n",
    "    We compute this classification by k-nearest-neighbors.  Our\n",
    "    training data (the data in which we look for neighbors) is the\n",
    "    given training_data table.\n",
    "    \"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "### Verifying that `classify` doesn't have bugs\n",
    "\n",
    "#### Question 8\n",
    "Verify that `classify` works as expected by replicating the simple example in question 6.  That is, classify an hypothetical movement with first-frame coordinates (0.8, 0.9), using a 1-nearest neighbor classifier with `train_two_features` as the training set.  Give the name `example_1NN_classification` to the predicted class of the observation.  Make sure it matches your answer to question 6!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "example_1NN_classification = ...\n",
    "example_1NN_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "#### Question 9\n",
    "Using the scatter plot you made in question 4, find a movement that would be classified as horizontal by a ***3***-nearest neighbor classifier, again with `train_two_features` as the training set.  Verify that `classify` produces the expected classification for that movement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "example_3NN_classification = ...\n",
    "example_3NN_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the accuracy\n",
    "Let us compute the accuracy of our classifier.\n",
    "\n",
    "First, we'll continue to imagine we have only 2 features rather than the full 90.  This will verify your answer to question 5.\n",
    "\n",
    "The next cell defines a function called `classify_all`.  It will be useful in answering the next question, so read its documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_all(test_data, training_data, k):\n",
    "    \"\"\"\n",
    "    Classifies each observation in test_data, using k-nearest neighbors with training_data.\n",
    "    \n",
    "    This function takes three arguments:\n",
    "     * test_data: A table of observations.  Each row contains the\n",
    "       attributes of one movement.  There should be no extra columns;\n",
    "       in particular, this table shouldn't include a column with the\n",
    "       true classes.\n",
    "     * training_data: A table of observations.  Must have one column\n",
    "       for each attribute in the test_data table, *plus* one column\n",
    "       at the end containing the true class of each observation.\n",
    "     * k: The number of neighbors to look at.\n",
    "    \n",
    "    It returns an array of strings, the classification of each row\n",
    "    in test_data.\n",
    "    \n",
    "    We compute these classification by k-nearest-neighbors.  Our\n",
    "    training data (the data in which we look for neighbors) is the\n",
    "    given training_data table.\n",
    "    \"\"\"\n",
    "    classifications = make_array()\n",
    "    for i in np.arange(test_data.num_rows):\n",
    "        classification = classify(\n",
    "            np.array(test_data.row(i)),\n",
    "            training_data,\n",
    "            k)\n",
    "        classifications = np.append(classifications, classification)\n",
    "    return classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "#### Question 10\n",
    "Create a table called `test_two_features` containing the observations in `test_movements` with only the first 2 features. This table should have the same columns as `train_two_features`. Compute the classifications of those observations using a 3-nearest neighbor classifier with `train_two_features` as the training set.  Then compute the proportion of those observations that are correct.\n",
    "\n",
    "**Note:** This might take around a minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_two_features = ...\n",
    "two_features_classifications = ...\n",
    "two_features_proportion_correct = ...\n",
    "two_features_proportion_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does that match what you wrote in question 5?\n",
    "\n",
    "Now let's try out the classifier with all 90 features.  We'd expect this to work better, because we're giving the classifier more information about each example.  (We've seen that some horizontal movements and vertical movements start out in the same place, but hopefully by the last frame those movements end up in very different places.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "#### Question 11\n",
    "Compute the accuracy of a 3-nearest neighbor classifier using `train_movements` as the training set and `test_movements` as the test set, *when all 90 features are used*.\n",
    "\n",
    "**Note:** This will take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_features_classifications = ...\n",
    "proportion_correct = ...\n",
    "proportion_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're interested, the next cell displays the movements in the test set that your classifier got wrong.  Would you have done better yourself?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wrong_examples = np.flatnonzero(all_features_classifications != test_movements.column(\"Movement type\"))\n",
    "interact(\n",
    "        display_hand,\n",
    "        example={str(i+num_train): i+num_train for i in wrong_examples},\n",
    "        frame=widgets.IntSlider(min=1, max=int((movements.num_columns-1)/2), step=1, value=1, msg_throttle=1),\n",
    "        display_truth=fixed(True));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "#### Question 12\n",
    "Would you predict that the accuracy would go up or down (relative to the result in question 11) if we used `train_movements` as both the training set and the test set?  Why?  You can try it yourself to verify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're done!  If you want more practice, try rewriting the `most_common` or `k_nearest_rows` functions for yourself.\n",
    "<div class=\"hide\">\\pagebreak</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Testing Relationship Ratings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout this part of the homework, we will be interested in learning how different factors can contribute to the rating couples give their relationship, on a scale of 1-5 (1 being most satisfied, and 5 being the least). \n",
    "\n",
    "To do this, we will be looking at the table that is loaded below. \n",
    "\n",
    "*Note:* The data in this table is quite dated. It only includes heterosexual relationships. A better dataset would contain a more accurate sample of couples. When drawing conclusions from data, it is important to be aware of biases that exist in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "couples = Table.read_table('couples.csv')\n",
    "couples "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the table above, we note that we should be able to test whether different factors can affect the relationship rating, from age to education. To begin, we are first going to investigate whether marital status has an effect on relationship rating. In order to accomplish this, we are going to do a permutation test! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "**Question 1** \n",
    "\n",
    "State the null and alternative hypothesis for such a test (assume we aren't trying to figure out ***how*** marital status affects relationship rating, just whether or not it does). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "for_assignment_type": "student"
   },
   "source": [
    "**Answer:**\n",
    "\n",
    "Null hypothesis:\n",
    "\n",
    "Alternate hypothesis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "**Question 2** \n",
    "\n",
    "Before we continue, we will have to talk about the notion of a contingency table. \n",
    "\n",
    "Define `contingency` to be a table where the rows represent unique values of the relationship ratings, the columns represent the unique values of marital status present in the table, and the values in each cell represent the number of individuals with a given marital status and relationship rating.\n",
    "\n",
    "*Hint:* Use `pivot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "contingency = ...\n",
    "contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = tests.grade('q2_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "**Question 3** \n",
    "\n",
    "It is difficult to identify a patterin in the above table, since our table has so many more married people than it does unmarried. To rectify this, we will instead compute proportions. \n",
    "\n",
    "Assign `contingency_prop` to a table with the same columns and rows, but the values are instead in proportions, i.e. the value in the cell corresponding to a relationship rating of 1 and marital status of \"married\" should be the proportion of married people who gave their relationship a 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "for_assignment_type": "student"
   },
   "outputs": [],
   "source": [
    "#The staff solution took 5 lines\n",
    "contingency_prop = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "**Question 4** \n",
    "\n",
    "Assign `tvd_marriages` to the total variational distance between the distributions of married people's relationship ratings and unmarried people's relationship ratings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tvd_marriages = ...\n",
    "tvd_marriages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = tests.grade('q2_4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "**Question 5** \n",
    "\n",
    "Let's get more general now. Define `tvd` which takes in \n",
    "\n",
    "- any table like `couples`\n",
    "- `conditions`: the name of a column like Relationship Rating\n",
    "- `values`: the name of a column like Marital Status\n",
    "\n",
    "The function should return the total variation distance between the distribution of conditions in the first unique value of values and the distribution of conditions in the second unique value of values (assume there are only two unique values)\n",
    "\n",
    "***Hint***: This looks daunting, but you are just generalizing your code from above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "for_assignment_type": "student"
   },
   "outputs": [],
   "source": [
    "def tvd(t, conditions, values):\n",
    "    return ...\n",
    "\n",
    "tvd(couples, 'Relationship Rating', 'Marital Status')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "**Question 6** \n",
    "\n",
    "Now that we have a valid test statistic, fill in the implementation of `permutation_test` below. It should run a permutation test to check whether conditions and values are related, where conditions and values are defined as above. See section [16.1](https://www.inferentialthinking.com/chapters/16/1/two-categorical-distributions.html) for details about the permutation test.\n",
    "\n",
    "The inputs to the function are:\n",
    "\n",
    "- `t`: a table containing our data\n",
    "- `conditions`: the name of the column in `t` representing our conditions\n",
    "- `values`: the name of the column in `t` representing our conditions\n",
    "- `repetitions`: the number of permutations we'd like to test\n",
    "- `statistic`: a test statistic function (such as `tvd`). \n",
    "\n",
    "The return value should be the p-value of seeing the observed value assuming the null hypothesis. Fill in the implementation as necessary; we have also provided code which allows you to see an empirical histogram of the distribution under the null. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def permutation_test(t, conditions, values, repetitions , statistic):\n",
    "    stats = ...\n",
    "\n",
    "    for i in np.arange(repetitions):\n",
    "        shuffled = ...\n",
    "        shuffled_table = Table().with_columns(conditions, t.column(conditions), values, shuffled.column(values))\n",
    "        stats = ...    \n",
    "\n",
    "    observation = ...\n",
    "    p_value = ...\n",
    "    \n",
    "    Table().with_column('Empirical distribution of TVD', stats).hist(bins=np.arange(-.02, .12, .02))\n",
    "    return p_value \n",
    "\n",
    "permutation_test(couples, 'Relationship Rating', 'Marital Status', 200, tvd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "**Question 7** \n",
    "\n",
    "Based on the above method, should we reject the null hypothesis that the relationship ratings and marital status areun correlated, or should we fail to reject? Why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Review of Table Methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this question, we are going to be going over some important table concepts that might be useful for the project. The dataset we will be using is `twitter_follows.csv`, which you can load below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "twitter_follows = Table.read_table('twitter_follows.csv')\n",
    "twitter_follows "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "**Question 1**\n",
    "\n",
    "Assign `least_followed` to the screename of the person who has the fewest followers. Do this using code; do not just inspect the table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "least_followed = ...\n",
    "least_followed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "**Question 2** \n",
    "\n",
    "Assign `most_followed` to the screename of the person who has the most followers now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_followed = ...\n",
    "most_followed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "**Question 3** \n",
    "\n",
    "Assign `avg_friends` to be the average number of friends across all of these users. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg_friends = ...\n",
    "avg_friends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "**Question 4** \n",
    "\n",
    "Define a function `comparison` which takes in a value and checks whether or not it's above `avg_friends`. If the value is greater than or equal to the average amount of friends, it returns True, otherwise False. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "for_assignment_type": "student"
   },
   "outputs": [],
   "source": [
    "def comparison(val):\n",
    "    ...\n",
    "comparison(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "**Question 5** \n",
    "\n",
    "Using apply, assign `avg_comparison` to a table which has an extra column called \"Above Average?\" which is values of true or false corresponding to whether or not the user has more or less friends than the average. Think about using the function you defined above, you **must** use apply for this question. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "above_avg_array = ...\n",
    "avg_comparison = twitter_follows.with_column('Above Average?', above_avg_array)\n",
    "avg_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The Gravity of Overfitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine you are an early natural scientist trying to understand how fast things fall.  You run experiments in which you drop an iron ball from a very tall cliff.  You want to know the relationship between the length of time (in seconds) the ball has been dropping and the distance the ball has fallen (in meters).  Isaac Newton will later predict, using calculus and a model of physics, that the relationship is\n",
    "\n",
    "$$\\text{distance fallen} = 0 + 0 \\times (\\text{time spent falling}) + \\frac{g}{2} \\times (\\text{time spent falling})^2,$$\n",
    "\n",
    "where $g$ is a constant related to the gravity of Earth.  But that hasn't happened yet.\n",
    "\n",
    "You drop your iron ball 7 times from the cliff.  Each time, you choose a time between 0 and 3 seconds (uniformly at random) and measure how far the ball has fallen after that long.  Your distance measurements rely on a human assistant with a stopwatch standing on the ground, so they are somewhat noisy.  That is, their measurements of the distance fallen aren't exactly equal to the actual distance fallen, but they're kinda close.\n",
    "\n",
    "You have three hypotheses:\n",
    "1. Distance is a linear function of falling time.  That means $\\text{distance fallen} = b + a \\times \\text{(time spent falling)}$ for some numbers $a$ and $b$.\n",
    "2. Distance is a quadratic function of falling time.  That means $\\text{distance fallen} = c + b \\times \\text{(time spent falling)} + a \\times \\text{(time spent falling)}^2$ for some numbers $a$, $b$, and $c$.\n",
    "3. Distance is a 6th-degree (\"hexic\") polynomial function of falling time.  (A 6th-degree polynomial has 7 parameters and can \"wiggle around\" a lot more than a linear or quadratic function.  You don't need to know anything else about polynomials to work on this question.)\n",
    "\n",
    "To test your hypotheses, you decide to find the function that fits the data most closely under each hypothesis - that is, the linear, quadratic, or 6th-degree polynomial function with the smallest mean squared error for these 7 points.\n",
    "\n",
    "The cell below loads the data, finds the best-fitting linear, quadratic, and 6th-degree polynomial functions for the dataset, and plots them.  (You don't need to know what it's doing, but the part that calls `minimize` should look somewhat familiar.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "falls = Table.read_table(\"falls.csv\")\n",
    "\n",
    "def polynomial(coefficients, x):\n",
    "    \"\"\"The value of a polynomial with the given coefficients, for input x.\"\"\"\n",
    "    num_coefficients = len(coefficients)\n",
    "    powers_of_x = x**np.arange(num_coefficients)\n",
    "    return sum(coefficients * powers_of_x)\n",
    "\n",
    "def polynomial_predictions(coefficients, x_values):\n",
    "    \"\"\"The values of a polynomial with the given coefficients, for each value in the array x_values.\"\"\"\n",
    "    def prediction(x):\n",
    "        return polynomial(coefficients, x)\n",
    "    return Table().with_columns(\"x\", x_values).apply(prediction, \"x\")\n",
    "\n",
    "def mse(coefficients):\n",
    "    \"\"\"The mean squared error when we use a polynomial with the given coefficients to predict distance fallen.\"\"\"\n",
    "    predictions = polynomial_predictions(coefficients, falls.column(\"falling time (s)\"))\n",
    "    return np.mean(((predictions - falls.column(\"distance fallen (m)\")))**2)\n",
    "\n",
    "def print_polynomial(coefficients):\n",
    "    xs = [\"*x^\" + str(power) if power > 1 else \"*x\" if power == 1 else \"\" for power in np.arange(len(coefficients))]\n",
    "    print(\"Best-fit degree-{:d} polynomial:\".format(len(coefficients)-1),\n",
    "          \" + \".join([\"{0: >#06.4g}\".format(c) + x for c, x in zip(coefficients, xs)]))\n",
    "\n",
    "def plot_polynomial(coefficients):\n",
    "    \"\"\"Plot the data, plus a polynomial with the given coefficients.\"\"\"\n",
    "    falling_times = np.arange(0, 3, .01)\n",
    "    predictions = polynomial_predictions(coefficients, falling_times)\n",
    "    falls.scatter(0, zorder=10, label=\"observations\")\n",
    "    plt.plot(falling_times, predictions, label=\"best-fit degree-{:d} polynomial\".format(len(coefficients)-1))\n",
    "    plt.legend(bbox_to_anchor=make_array(2, .6))\n",
    "    plt.ylim(-10, 50)\n",
    "\n",
    "for num_coefficients in make_array(2, 3, 7):\n",
    "    best_polynomial = minimize(mse, start=np.zeros(num_coefficients), array=True, method='SLSQP', options={'ftol': 1e-10})\n",
    "    print_polynomial(best_polynomial)\n",
    "    plot_polynomial(best_polynomial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The 6th-degree polynomial doesn't actually have a discontinuity between 2.1 and 2.7; it just varies so sharply that we couldn't fit the whole curve on the same scale as the linear and quadratic curves without making those curves look very flat.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "#### Question 1\n",
    "By examining the three plots, rank the curves by mean squared residual on the 7 data points, least to greatest.  If you think there is a tie between any of the curves, say that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You aren't convinced by the results of this experiment, so you decide to run a second copy.  You drop 7 iron balls for random amounts of time between 0 and 3 seconds and record the distance fallen.  Then you check how accurately the three functions computed above (the same 3 curves pictured in the plots) predicted the distance fallen for these 7 new trials.  You compute the MSE for each one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "#### Question 2\n",
    "Rank the 3 curves by the mean squared error you'd *expect* to see for these 7 new trials, least to greatest.  If you think there is a tie between any of the curves, say that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with the 6th-degree polynomial is that it's able to \"wiggle around\" too much to fit the data we train it on.  1-nearest neighbor classifiers have an analogous problem.\n",
    "\n",
    "The cell below loads a (synthetic) dataset about art forgery.  Each row is a painting that is either a forgery or an original painting by the (fictional) Impressionist artist Edgar Detas.  Brush strokes are thought to be highly personal and difficult to replicate, so for each painting, we have measured two characteristics: the average width of brush strokes (in millimeters) and the average length of brush strokes (also in millimeters).\n",
    "\n",
    "Gold dots represent real paintings. Blue dots represent forgeries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "forgeries_sample = Table.read_table(\"forgeries_sample.csv\")\n",
    "forgeries_sample.scatter(\"Stroke width\", \"Stroke length\", colors=\"Color\")\n",
    "\n",
    "def set_graph_dimensions():\n",
    "    # This function just sets the width and height of the graph.\n",
    "    # We define it here so we can reuse it in the next cell.\n",
    "    plt.xlim(0, 10)\n",
    "    plt.ylim(2, 14)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "\n",
    "set_graph_dimensions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell shows the decision regions of a 1-nearest neighbor classifier and a 5-nearest neighbor classifier on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_classifier(k, training):\n",
    "    \"\"\"Train a k-NN classifier on the given art training data.\"\"\"\n",
    "    attributes = training.select(\"Stroke width\", \"Stroke length\").to_df().as_matrix()\n",
    "    classes = training.column(\"Forgery\")\n",
    "    def classify(w, l):\n",
    "        distances = np.sum((attributes - make_array(w, l))**2, axis=1)\n",
    "        closest_example_indices = np.argsort(distances)[:k]\n",
    "        return 2*sum(classes[closest_example_indices]) >= k\n",
    "    return classify\n",
    "\n",
    "def display_decision_region(classifier):\n",
    "    xs = np.arange(.5, 9, .1)\n",
    "    ys = np.arange(4, 13, .1)\n",
    "    x_grid, y_grid = np.meshgrid(xs, ys)\n",
    "    decisions = Table().with_columns(\n",
    "        \"Stroke width\", x_grid.flatten(),\n",
    "        \"Stroke length\", y_grid.flatten())\n",
    "    decisions = decisions\\\n",
    "        .with_column(\"Forgery\", decisions.apply(classifier, make_array(0, 1)))\\\n",
    "        .join(\"Forgery\", Table().with_columns(\"Forgery\", make_array(0, 1), \"Color\", make_array(\"Gold\", \"Blue\")))\\\n",
    "        .select(\"Stroke width\", \"Stroke length\", \"Color\")\n",
    "    decisions.scatter(\"Stroke width\", \"Stroke length\", colors=\"Color\", alpha=.4, s=2)\n",
    "    plt.scatter(\n",
    "        forgeries_sample.column(\"Stroke width\"),\n",
    "        forgeries_sample.column(\"Stroke length\"),\n",
    "        c=forgeries_sample.column(\"Color\"),\n",
    "        lw=1,\n",
    "        edgecolor=\"black\")\n",
    "    set_graph_dimensions()\n",
    "    \n",
    "one_nn = make_classifier(1, forgeries_sample)\n",
    "five_nn = make_classifier(5, forgeries_sample)\n",
    "display_decision_region(one_nn)\n",
    "display_decision_region(five_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "#### Question 3\n",
    "Suppose we use each classifier to classify the paintings in `forgery_sample`.  (Yes, the training set.)  Rank the classifiers by the proportion of **correct** guesses they make, **greatest to least**.  (Look at the plots generated by the cells above to answer this question.  You can run the classifiers to verify your answer if you want.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision region of the 1-nearest neighbor classifier is pocked with little holes.  For example, notice the two regions in the bottom-left where the 1-nearest neighbor classifier classifies paintings as forgeries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "#### Question 4\n",
    "Suppose we find some **new** paintings.  We're not sure whether they are Detas originals or forgeries, so we ask our 2 classifiers.  For new paintings that fall in those two bottom-left regions, do the classifiers make different guesses?  If so, which classifier do you think makes better guesses?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For your convenience, you can run this cell to run all the tests at once!\n",
    "import os\n",
    "print(\"Running all tests...\")\n",
    "_ = [tests.grade(q[:-3]) for q in os.listdir(\"tests\") if q.startswith('q')]\n",
    "print(\"Finished running all tests.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

